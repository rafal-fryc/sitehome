---
phase: 01-data-pipeline
plan: 03
type: execute
wave: 2
depends_on:
  - "01-01"
files_modified:
  - scripts/build-provisions.ts
  - scripts/build-ftc-data.ts
  - package.json
autonomous: true
requirements:
  - PIPE-05
  - PIPE-07
  - PIPE-08

must_haves:
  truths:
    - "scripts/build-provisions.ts reads tagged source files and emits topic-sharded JSON files"
    - "build-ftc-data.ts enhanced ftc-cases.json includes statutory_topics, practice_areas, industry_sectors, remedy_types per case"
    - "package.json has build:classify, build:provisions, and build:data scripts"
    - "No classification logic runs at build time — build-provisions.ts only reads pre-written tags"
    - "Each topic shard file reports its own provision count during build"
    - "The categories field is preserved in enhanced ftc-cases.json for backward compatibility"
  artifacts:
    - path: "scripts/build-provisions.ts"
      provides: "Topic-sharded provision file generator"
      min_lines: 100
      contains: "ProvisionShardFile"
    - path: "public/data/provisions/"
      provides: "Directory for topic-sharded provision JSON files"
    - path: "package.json"
      provides: "build:data npm script"
      contains: "build:data"
  key_links:
    - from: "scripts/build-provisions.ts"
      to: "public/data/ftc-files/"
      via: "readFileSync per case file"
      pattern: "readFileSync|readdirSync"
    - from: "scripts/build-provisions.ts"
      to: "public/data/provisions/"
      via: "writeFileSync per topic shard"
      pattern: "writeFileSync.*provisions"
    - from: "scripts/build-ftc-data.ts"
      to: "public/data/ftc-cases.json"
      via: "enhanced output with new fields"
      pattern: "statutory_topics|industry_sectors"
---

<objective>
Write scripts/build-provisions.ts (topic-sharded provision file generator), enhance scripts/build-ftc-data.ts to emit the new classification fields, and add build:classify, build:provisions, and build:data npm scripts to package.json.

Purpose: This is the build-time step that runs after classification. It reads the tagged source files and produces the static JSON artifacts the browser depends on: per-topic provision shards under public/data/provisions/, and an enhanced ftc-cases.json. Zero classification logic runs in this script — it only reads pre-written tags (PIPE-08).

Output: scripts/build-provisions.ts, updated scripts/build-ftc-data.ts, updated package.json.
</objective>

<execution_context>
@C:/Users/rafst/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/rafst/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/types/ftc.ts
@scripts/build-ftc-data.ts
@.planning/phases/01-data-pipeline/01-RESEARCH.md
@.planning/phases/01-data-pipeline/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create scripts/build-provisions.ts — topic-sharded provision file generator</name>
  <files>scripts/build-provisions.ts</files>
  <action>
    Create scripts/build-provisions.ts. This script reads all tagged source files from public/data/ftc-files/ and writes per-topic provision shard files to public/data/provisions/.

    **Imports:** Node.js built-ins (fs, path). Type imports from '../src/types/ftc.js': StatutoryTopic, PracticeArea, ProvisionRecord, ProvisionShardFile.

    **Logic:**

    1. Read all .json files from public/data/ftc-files/ (same as classify script).

    2. For each file, parse the case JSON. If case_info.statutory_topics is undefined (not yet classified), print a warning and skip: "WARN: [filename] not yet classified — run build:classify first".

    3. For each provision in order.provisions, build a ProvisionRecord (denormalized):
       ```typescript
       {
         provision_number: provision.provision_number,
         title: provision.title,
         category: provision.category,
         summary: provision.summary ?? '',
         statutory_topics: provision.statutory_topics ?? [],
         practice_areas: provision.practice_areas ?? [],
         remedy_types: provision.remedy_types ?? [],
         // Denormalized case context:
         case_id: caseData.case_info.id ?? filename.replace('.json', ''),
         company_name: caseData.case_info.company_name,
         date_issued: caseData.case_info.date_issued,
         year: Number(caseData.case_info.date_issued?.slice(0, 4)),
         administration: caseData.case_info.administration ?? '',
         legal_authority: caseData.case_info.legal_authority ?? '',
         ftc_url: caseData.case_info.ftc_url,
         docket_number: caseData.case_info.docket_number ?? '',
       }
       ```

    4. Accumulate all ProvisionRecords into a Map: topic -> ProvisionRecord[]. A provision with multiple statutory_topics appears in EACH of those topic shards. Also accumulate into a "all-provisions" bucket (for potential flat file if needed). Use the statutory_topics array on the provision for shard assignment.

    5. Additionally create practice-area shards keyed by practice area slug (e.g., "data-security", "ai-automated-decision-making"). Apply slugification: lowercase, replace "/" and spaces with "-", collapse multiple dashes.

    6. After processing all files, write shard files. Output directory: public/data/provisions/ (create with mkdirSync recursive if it doesn't exist).

       Topic shard filenames: `[slug]-provisions.json` where slug is derived from the topic value:
       - "COPPA" → "coppa-provisions.json"
       - "FCRA" → "fcra-provisions.json"
       - "GLBA" → "glba-provisions.json"
       - "Health Breach Notification" → "health-breach-notification-provisions.json"
       - "CAN-SPAM" → "can-spam-provisions.json"
       - "TCPA" → "tcpa-provisions.json"
       - "TSR" → "tsr-provisions.json"
       - "Section 5 Only" → "section-5-only-provisions.json"

       Practice area shard filenames follow the same slugification pattern.

       Each output file conforms to ProvisionShardFile: { topic, generated_at: new Date().toISOString(), total_provisions, provisions }

    7. Print a summary report to stdout:
       ```
       Provisions build complete
       ─────────────────────────────────
       coppa-provisions.json             47 provisions  (XX KB)
       fcra-provisions.json             312 provisions  (XX KB)
       ...
       Total provisions across all shards: XXXX (provisions appear in multiple shards if multi-tagged)
       ─────────────────────────────────
       ```
       For each shard file, calculate the JSON byte size and report it.

    8. Exit with code 1 if any case files were unclassified (warning count > 0) so CI pipelines can detect the problem.

    Use the same `writeJSONSafe` pattern (write to .tmp then rename) from the research doc to avoid partial writes.
  </action>
  <verify>Run: npx tsx scripts/build-provisions.ts 2>&1. If source files are not yet classified, it should print WARN lines and exit with code 1. TypeScript must compile: npx tsc --noEmit with zero errors. Check that public/data/provisions/ directory is created by the script (even if empty on first run with unclassified files).</verify>
  <done>scripts/build-provisions.ts exists, compiles without TypeScript errors, creates public/data/provisions/ directory, and either writes shard files (if source files are classified) or reports warnings and exits with code 1 (if source files are not yet classified). Summary table is printed to stdout.</done>
</task>

<task type="auto">
  <name>Task 2: Enhance build-ftc-data.ts output and add npm scripts to package.json</name>
  <files>scripts/build-ftc-data.ts, package.json</files>
  <action>
    **Part A — Enhance scripts/build-ftc-data.ts:**

    The existing script produces ftc-cases.json with FTCCaseSummary records. Enhance it to read classification tags from source files and add them to each case summary.

    Read the current scripts/build-ftc-data.ts first (already in context). The script reads each source file and builds a case summary object. Modify the case summary construction to:

    1. After parsing the case JSON, read the classification fields if present:
       ```typescript
       const statutory_topics = caseData.case_info?.statutory_topics ?? [];
       const practice_areas = caseData.case_info?.practice_areas ?? [];
       const industry_sectors = caseData.case_info?.industry_sectors ?? [];
       ```

    2. Compute remedy_types: collect all unique remedy_types from all provisions in order.provisions[].remedy_types. Deduplicate.

    3. Compute provision_counts_by_topic: for each statutory topic in statutory_topics, count how many provisions in this case have that topic in their statutory_topics array. Return as Record<string, number>.

    4. Add these fields to the case summary object emitted in the output:
       ```typescript
       statutory_topics,
       practice_areas,
       industry_sectors,
       remedy_types,
       provision_counts_by_topic,
       ```

    5. Keep the existing `categories` field calculation UNCHANGED — it remains in the output for backward compatibility. The existing UI components still read `case.categories` for analytics display. Phase 2 will migrate them.

    6. NOTE: build-ftc-data.ts inlines its own types (comment says "to avoid path alias issues in tsx scripts"). Follow the same pattern — do NOT import from src/types/ftc.ts in this script; instead, inline the new field types as local TypeScript types or interfaces (e.g., `type StatutoryTopic = string` is sufficient since we just pass through values).

    The script should print a summary line after writing: "Enhanced ftc-cases.json: X cases, Y with statutory topics, Z with industry sectors"

    **Part B — Add npm scripts to package.json:**

    Read the current package.json scripts section. Add three new scripts:
    ```json
    "build:classify": "npx tsx scripts/classify-provisions.ts",
    "build:provisions": "npx tsx scripts/build-provisions.ts",
    "build:data": "npm run build:ftc-data && npm run build:provisions"
    ```

    The "build:data" script runs build:ftc-data (enhanced, produces enhanced ftc-cases.json) followed by build:provisions (reads tagged source files, produces sharded provision files). Note: build:classify is a SEPARATE command that the user runs interactively once before build:data — it does NOT run as part of build:data because it requires human supervision of the classification agent (CONTEXT.md decision: classification is supervised).

    Add a comment in package.json or in the script name to make this clear — but package.json does not support comments in the JSON "scripts" object, so make the script name self-explanatory.
  </action>
  <verify>
    1. `npx tsc --noEmit` — zero errors
    2. `npm run build:ftc-data` — runs successfully, outputs "Enhanced ftc-cases.json: X cases..."
    3. Check public/data/ftc-cases.json — if source files are classified, the case objects should include statutory_topics, practice_areas, industry_sectors fields. If not classified, these fields should be empty arrays (not missing).
    4. `npm run build:data --dry-run` or just check package.json has "build:data" key.
    5. `cat package.json | grep build:data` — should show the script.
  </verify>
  <done>scripts/build-ftc-data.ts emits enhanced case objects with statutory_topics, practice_areas, industry_sectors, remedy_types, provision_counts_by_topic fields alongside the existing categories field. package.json has build:classify, build:provisions, and build:data scripts. npx tsc --noEmit passes.</done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` — zero errors
2. `cat package.json | python3 -m json.tool | grep -A2 build:data` — shows the script
3. `npm run build:ftc-data 2>&1 | tail -5` — shows completion message
4. `node -e "const d = require('./public/data/ftc-cases.json'); const c = d.cases[0]; console.log(Object.keys(c).filter(k => ['statutory_topics','industry_sectors','remedy_types'].includes(k)))"` — shows the new fields exist on cases
</verification>

<success_criteria>
- scripts/build-provisions.ts: creates public/data/provisions/, writes topic-sharded .json files, reports sizes
- scripts/build-ftc-data.ts: enhanced output includes statutory_topics, practice_areas, industry_sectors, remedy_types, provision_counts_by_topic per case; existing categories field preserved
- package.json: has build:classify, build:provisions, build:data scripts
- npx tsc --noEmit passes with zero errors
</success_criteria>

<output>
After completion, create `.planning/phases/01-data-pipeline/01-03-SUMMARY.md`
</output>
