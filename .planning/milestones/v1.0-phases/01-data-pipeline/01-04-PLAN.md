---
phase: 01-data-pipeline
plan: 04
type: execute
wave: 3
depends_on:
  - "01-02"
  - "01-03"
files_modified:
  - public/data/ftc-files/*.json
  - public/data/provisions/*.json
  - public/data/ftc-cases.json
  - .planning/phases/01-data-pipeline/distribution-stats.txt
autonomous: false
requirements:
  - PIPE-01
  - PIPE-02
  - PIPE-03
  - PIPE-04
  - PIPE-05
  - PIPE-06
  - PIPE-07

must_haves:
  truths:
    - "All 293 source files in public/data/ftc-files/ have statutory_topics, practice_areas, industry_sectors tags"
    - "Running npm run build:data produces sharded provision files with zero errors"
    - "Each topic shard in public/data/provisions/ contains plausible provision counts"
    - "No single practice area accounts for more than 60% of all provisions"
    - "COPPA provisions exist, Data Security provisions exist in their respective shards"
    - "A sample of 20-30 manually inspected cases have correct statutory topic and industry sector tags"
    - "ftc-cases.json is parseable and cases have statutory_topics arrays"
    - "PIPE-06 is acknowledged as deferred to Phase 5 — no ftc-patterns.json is produced"
  artifacts:
    - path: "public/data/provisions/"
      provides: "Topic-sharded provision JSON files"
      contains: "coppa-provisions.json"
    - path: "public/data/ftc-cases.json"
      provides: "Enhanced case summaries with classification fields"
    - path: "public/data/ftc-files/"
      provides: "293 classified source files with tags written in"
    - path: ".planning/phases/01-data-pipeline/distribution-stats.txt"
      provides: "Distribution statistics for human spot-check"
  key_links:
    - from: "public/data/ftc-files/"
      to: "public/data/provisions/"
      via: "npm run build:provisions reads tags written by classify-provisions.ts"
      pattern: "statutory_topics|practice_areas"
    - from: "public/data/ftc-files/"
      to: "public/data/ftc-cases.json"
      via: "npm run build:ftc-data reads classification fields from source"
      pattern: "statutory_topics|industry_sectors"
---

<objective>
Run the classification script against all 293 FTC source files, then run `npm run build:data` to produce the sharded provision files and enhanced ftc-cases.json. Verify the output distribution is plausible and spot-check a sample of 20-30 cases across different topics and years. This plan also formally acknowledges that PIPE-06 (ftc-patterns.json) is deferred to Phase 5 per CONTEXT.md.

Purpose: This is the execution and validation step. The scripts are written — now we run them and confirm the data pipeline produces correct, usable output.

Output: 293 classified source files, topic-sharded provision files under public/data/provisions/, enhanced ftc-cases.json, human-verified distribution statistics.
</objective>

<execution_context>
@C:/Users/rafst/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/rafst/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-data-pipeline/01-RESEARCH.md
@.planning/phases/01-data-pipeline/01-02-SUMMARY.md
@.planning/phases/01-data-pipeline/01-03-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Run classification script and build pipeline, then produce distribution statistics</name>
  <files>public/data/ftc-files/*.json, public/data/provisions/*.json, public/data/ftc-cases.json, .planning/phases/01-data-pipeline/distribution-stats.txt</files>
  <action>
    Run the classification and build pipeline in sequence, then analyze output distribution.

    **Step 1 — Run classification:**
    ```bash
    npm run build:classify 2>&1 | tee /tmp/classify-output.log
    ```
    Watch for ERR lines in the output. The script should print "OK" or "SKIP" per file. If errors occur, read the error messages — most likely causes: JSON parse errors in source files (OCR-corrupted files noted in research), or missing fields. Log ERR lines but do NOT stop — the script handles per-file errors gracefully. After completion, print the summary line (classified / skipped / errors count).

    If errors > 5% of files (more than ~15 files), pause and diagnose before continuing.

    **Step 2 — Run build pipeline:**
    ```bash
    npm run build:data 2>&1 | tee /tmp/build-output.log
    ```
    This runs build:ftc-data then build:provisions. Both should complete without errors. The build:provisions step prints a shard size table.

    **Step 3 — Produce distribution statistics:**
    Write a small inline Node.js analysis (using node -e or a temporary analysis script at scripts/analyze-distribution.ts, deleted after use) to compute:

    a. **Statutory topic distribution from ftc-cases.json:**
       Count cases per statutory_topic. Report: topic name → case count. Flag if any single topic > 150 cases (that would be unusual).

    b. **Practice area distribution:**
       Iterate all provision shard files in public/data/provisions/. For each practice-area shard, read total_provisions. Report the distribution. CRITICAL CHECK: If "Privacy" or "data-security" shard contains >60% of total provisions across all shards, log a WARNING — this is the "Privacy swallowing everything" failure mode documented in the research.

    c. **Remedy type distribution:**
       Read ftc-cases.json, extract all remedy_types from all cases (flattened), count by type. Report each type's count.

    d. **Industry sector distribution:**
       Extract industry_sectors from ftc-cases.json, count per sector. Report.

    e. **Shard file sizes:**
       List public/data/provisions/*.json with file sizes in KB. Flag any shard > 2000 KB (2 MB raw) as potentially needing sub-sharding in Phase 2.

    f. **Classification completeness:**
       Count how many of the 293 source files have statutory_topics defined. Should be 293 minus any ERR files.

    Print all statistics to stdout in a readable table format. Write the full report to .planning/phases/01-data-pipeline/distribution-stats.txt.

    **PIPE-06 acknowledgment:**
    Include in the report: "PIPE-06 (ftc-patterns.json): DEFERRED to Phase 5 per CONTEXT.md decision. No pattern detection runs in Phase 1."

    **Backward compatibility check:**
    Run the following to confirm both old and new fields exist on case objects:
    ```bash
    node -e "const d = JSON.parse(require('fs').readFileSync('public/data/ftc-cases.json','utf-8')); const c = d.cases[0]; console.log('Old categories:', c.categories?.length ?? 'MISSING'); console.log('New statutory_topics:', c.statutory_topics?.length ?? 'MISSING');"
    ```
    Both must print a number, not "MISSING".
  </action>
  <verify>
    1. `ls public/data/provisions/*.json | wc -l` — at least 8 shard files (one per statutory topic)
    2. `node -e "const d = JSON.parse(require('fs').readFileSync('public/data/provisions/coppa-provisions.json','utf-8')); console.log('COPPA provisions:', d.total_provisions)"` — should be > 0
    3. `cat .planning/phases/01-data-pipeline/distribution-stats.txt` — shows the full distribution report with all six sections
    4. `node -e "const d = JSON.parse(require('fs').readFileSync('public/data/ftc-cases.json','utf-8')); const withTopics = d.cases.filter(c => c.statutory_topics && c.statutory_topics.length > 0); console.log('Cases with topics:', withTopics.length, '/', d.cases.length)"` — at least 200 cases with topics
    5. Backward compatibility: both `categories` and `statutory_topics` fields present on case objects (not "MISSING")
  </verify>
  <done>All 293 (minus ERR files) source files are classified. public/data/provisions/ contains statutory-topic and practice-area shard files. ftc-cases.json has both old categories field and new statutory_topics/practice_areas/industry_sectors fields. distribution-stats.txt written to .planning/phases/01-data-pipeline/.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Human spot-check classification quality and distribution across 20-30 cases</name>
  <what-built>
    Complete data pipeline output:
    - 293 FTC source files classified with statutory_topics, practice_areas, remedy_types, industry_sectors
    - Topic-sharded provision files in public/data/provisions/
    - Enhanced ftc-cases.json with classification fields (backward-compatible — old categories field preserved)
    - Distribution statistics in .planning/phases/01-data-pipeline/distribution-stats.txt
    - PIPE-06 acknowledged as deferred to Phase 5
  </what-built>
  <how-to-verify>
    1. Read the distribution report:
       ```
       cat .planning/phases/01-data-pipeline/distribution-stats.txt
       ```
       Check: Does the topic distribution look plausible? COPPA cases ~20-30, FCRA ~40-50. Data Security should be a significant practice area. No single practice area at >60%.

    2. Spot-check 20-30 source files across different topics, years, and company types. For each, open the JSON and verify the tags make sense given the case content. Suggested coverage:
       - 5-7 COPPA cases (children's app enforcement) — should have "COPPA" in statutory_topics and "Technology" or "Education" in industry_sectors
       - 5-7 data security / breach cases — should have "Data Security" in practice_areas and a breach-related remedy type
       - 3-5 credit reporting cases — should have "FCRA" in statutory_topics and "Financial Services" in industry_sectors
       - 3-5 telemarketing cases — should have "TSR" or "TCPA" in statutory_topics and "Telemarketing" in practice_areas
       - 3-5 general Section 5 deceptive practices cases — should have "Section 5 Only" in statutory_topics
       - 2-3 AI/algorithmic cases (if any exist in dataset) — should have "AI / Automated Decision-Making" in practice_areas
       Across these 20-30 cases, count how many are correctly tagged. If fewer than 80% look correct, the classification needs a correction pass before Phase 2.

    3. CRITICAL: Check if "Privacy" is over-represented. If the Privacy practice area shard contains >50% of all provisions across all shards, the LLM prompts are too broad. Note this for correction.

    4. Check shard file sizes from the report — note any shards >2 MB (raw) that will need sub-sharding when Phase 2 loads them in the browser.

    5. Run `npm run dev` and navigate to the FTC analytics page — the existing page should still load without errors (it reads the old `categories` field from ftc-cases.json which is preserved).
  </how-to-verify>
  <resume-signal>
    Type "approved" if classification quality is acceptable for Phase 2 (UI) work (80%+ of spot-checked cases correctly tagged).
    Type "fix: [description]" if specific issues need correction before proceeding (e.g., "fix: Privacy is 70% of all provisions — reclassify", "fix: COPPA cases tagged as Section 5 Only").
    Type "partial: [description]" if acceptable overall but with noted concerns to track in Phase 2.
  </resume-signal>
</task>

</tasks>

<verification>
Phase 1 complete when:
1. `npm run build:data` runs without errors end-to-end
2. COPPA and Data Security provision shards both contain > 0 provisions
3. No single practice area shard contains > 60% of total provisions
4. ftc-cases.json parses successfully and cases include both categories (old) and statutory_topics (new) fields
5. TypeScript compiles: `npx tsc --noEmit` passes with zero errors
6. Human spot-check of 20-30 cases approved (80%+ correctly tagged)

PIPE-06 status: Acknowledged as deferred to Phase 5. No ftc-patterns.json produced in Phase 1.
</verification>

<success_criteria>
Running `npm run build:data` from the project root:
- Reads 293 tagged source files from public/data/ftc-files/
- Writes enhanced public/data/ftc-cases.json (cases include statutory_topics, practice_areas, industry_sectors, remedy_types, provision_counts_by_topic alongside existing categories)
- Writes at least 8 topic-sharded provision files to public/data/provisions/
- Prints shard size report to stdout
- Completes without errors

Distribution sanity checks pass:
- COPPA provisions exist (>0)
- Data Security provisions exist (>0)
- No single topic/practice-area shard contains >60% of total provisions
- Human spot-check on 20-30 cases confirms plausible classification (80%+ correct)

TypeScript compiles without errors.
</success_criteria>

<output>
After completion, create `.planning/phases/01-data-pipeline/01-04-SUMMARY.md`
</output>
